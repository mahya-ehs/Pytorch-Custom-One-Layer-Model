{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CnC1oyQu7XW"
      },
      "source": [
        "**import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-LvTJqgOk1u9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import sklearn.cluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ndt0t9OOujY",
        "outputId": "4a50685a-8b4c-4a65-a5e5-ad5125ee3e22"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6ZAS96Au_nl"
      },
      "source": [
        "**custom linear layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Z2nvzl6UMBtx"
      },
      "outputs": [],
      "source": [
        "class LinearFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, bias=None):\n",
        "        ctx.save_for_backward(input, weight, bias)\n",
        "        output = input.mm(weight.t()) + bias\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        #grad_output -> dLoss/dy_hat\n",
        "        input, weight, bias = ctx.saved_tensors\n",
        "        grad_input = grad_weight = grad_bias = None\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_input = grad_output.mm(weight)\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_weight = grad_output.t().mm(input)\n",
        "        if bias is not None and ctx.needs_input_grad[2]:\n",
        "            grad_bias = grad_output.sum(0)\n",
        "\n",
        "        return grad_input, grad_weight, grad_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hMozZTQulBS_"
      },
      "outputs": [],
      "source": [
        "class MyLinearLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(output_size, input_size))\n",
        "        self.bias = nn.Parameter(torch.randn(output_size))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return LinearFunction.apply(input, self.weight, self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sd1BmHRkTG"
      },
      "source": [
        "**MSE Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lViP9z0IRnGK"
      },
      "outputs": [],
      "source": [
        "class MSELossFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, y_pred, y):\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        ctx.save_for_backward(y_pred, y)\n",
        "        loss = ( (y - y_pred)**2 ).mean()\n",
        "\n",
        "        return  loss\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        y_pred, y = ctx.saved_tensors\n",
        "        grad_input = 2 * (y_pred - y) / y_pred.shape[0]\n",
        "        return grad_input, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NIxYwGR5SBoi"
      },
      "outputs": [],
      "source": [
        "class MSELoss(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return MSELossFunction.apply(input, target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeN9ai_-vCk3"
      },
      "source": [
        "**custom cross entropy loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8FQCcUmlMMy1"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLossFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, output, target):\n",
        "        output_softmax = F.log_softmax(output, dim=1)\n",
        "\n",
        "        one_hot_labels = torch.zeros_like(output_softmax)\n",
        "        one_hot_labels.scatter_(1, target.view(-1, 1), 1)\n",
        "\n",
        "        ctx.save_for_backward(output_softmax, one_hot_labels)\n",
        "\n",
        "        loss = torch.sum(-one_hot_labels * output_softmax, dim=1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output, target = ctx.saved_tensors\n",
        "\n",
        "        grad_input = (F.softmax(output, dim=1) - target)/output.shape[0]\n",
        "\n",
        "        return grad_input, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lDO_LUmulIV6"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return CrossEntropyLossFunction.apply(input, target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVMObunmvHBt"
      },
      "source": [
        "**model with one layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5gFUSByTuQLb"
      },
      "outputs": [],
      "source": [
        "class BasicModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.layer(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGhzaJ8Cu4n7"
      },
      "source": [
        "**dataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7SeX1eOQlabM"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM2sOjBaoCxb"
      },
      "source": [
        "**model and loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NHShX8ANu335"
      },
      "outputs": [],
      "source": [
        "input_size = 784\n",
        "output_size = 10\n",
        "\n",
        "model = BasicModel(input_size, output_size)\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PpmrZn8oNOz"
      },
      "source": [
        "**train function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zRiL86aRlXYQ"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, loss_fn, optimizer, num_epochs=50):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        num_samples = len(dataloader.dataset)\n",
        "        num_batches = len(dataloader)\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for index, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            running_corrects += torch.sum(preds == labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = (running_loss / num_batches)\n",
        "        epoch_acc = (running_corrects / num_samples) * 100\n",
        "        print(f\"epoch {epoch+1} -> Loss: {epoch_loss}, accuracy: {epoch_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ6goBDBlfwY",
        "outputId": "b5254671-99a0-4ebf-e3d0-96f5f2a7934a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 -> Loss: 1.3391249592997816, accuracy: 85.67166900634766\n",
            "epoch 2 -> Loss: 1.244700111146929, accuracy: 87.70000457763672\n",
            "epoch 3 -> Loss: 1.2359495929190154, accuracy: 87.99833679199219\n",
            "epoch 4 -> Loss: 1.2293428018657384, accuracy: 88.1500015258789\n",
            "epoch 5 -> Loss: 1.2511449682353528, accuracy: 88.31666564941406\n",
            "epoch 6 -> Loss: 1.2114849072466018, accuracy: 88.60000610351562\n",
            "epoch 7 -> Loss: 1.2187365383378415, accuracy: 88.59833526611328\n",
            "epoch 8 -> Loss: 1.1917533148040396, accuracy: 88.72833251953125\n",
            "epoch 9 -> Loss: 1.1643823875563104, accuracy: 88.84500122070312\n",
            "epoch 10 -> Loss: 1.1817265916774586, accuracy: 88.70166778564453\n",
            "epoch 11 -> Loss: 1.1429401946061455, accuracy: 89.05833435058594\n",
            "epoch 12 -> Loss: 1.1819109857908443, accuracy: 88.91666412353516\n",
            "epoch 13 -> Loss: 1.157093072929648, accuracy: 89.01167297363281\n",
            "epoch 14 -> Loss: 1.153664670836951, accuracy: 88.99166870117188\n",
            "epoch 15 -> Loss: 1.2006137848361087, accuracy: 88.92166900634766\n",
            "epoch 16 -> Loss: 1.2148083233456217, accuracy: 88.98666381835938\n",
            "epoch 17 -> Loss: 1.2209122812848037, accuracy: 88.9800033569336\n",
            "epoch 18 -> Loss: 1.1825857373204693, accuracy: 89.13166809082031\n",
            "epoch 19 -> Loss: 1.1636236363461911, accuracy: 89.16000366210938\n",
            "epoch 20 -> Loss: 1.1998066216000298, accuracy: 89.02333068847656\n",
            "epoch 21 -> Loss: 1.156100654673985, accuracy: 89.24500274658203\n",
            "epoch 22 -> Loss: 1.1561683426513822, accuracy: 89.21499633789062\n",
            "epoch 23 -> Loss: 1.1748496878630064, accuracy: 89.03833770751953\n",
            "epoch 24 -> Loss: 1.162031447448865, accuracy: 89.24000549316406\n",
            "epoch 25 -> Loss: 1.1663430823223677, accuracy: 89.44833374023438\n",
            "epoch 26 -> Loss: 1.1822008675317774, accuracy: 89.21666717529297\n",
            "epoch 27 -> Loss: 1.1921276173242596, accuracy: 89.18167114257812\n",
            "epoch 28 -> Loss: 1.218061813246673, accuracy: 89.10166931152344\n",
            "epoch 29 -> Loss: 1.1523749587753578, accuracy: 89.3933334350586\n",
            "epoch 30 -> Loss: 1.1528527753582514, accuracy: 89.3316650390625\n",
            "epoch 31 -> Loss: 1.135826482370035, accuracy: 89.42500305175781\n",
            "epoch 32 -> Loss: 1.1298239516940263, accuracy: 89.35000610351562\n",
            "epoch 33 -> Loss: 1.1042423729719257, accuracy: 89.57000732421875\n",
            "epoch 34 -> Loss: 1.130081778257536, accuracy: 89.336669921875\n",
            "epoch 35 -> Loss: 1.1101034003279995, accuracy: 89.42166900634766\n",
            "epoch 36 -> Loss: 1.1706331516007906, accuracy: 89.39000701904297\n",
            "epoch 37 -> Loss: 1.1298424743483517, accuracy: 89.51499938964844\n",
            "epoch 38 -> Loss: 1.1521262186152468, accuracy: 89.33833312988281\n",
            "epoch 39 -> Loss: 1.1602599757399832, accuracy: 89.32333374023438\n",
            "epoch 40 -> Loss: 1.1612629213852923, accuracy: 89.30833435058594\n",
            "epoch 41 -> Loss: 1.1160317733615779, accuracy: 89.69166564941406\n",
            "epoch 42 -> Loss: 1.1243776197332753, accuracy: 89.51166534423828\n",
            "epoch 43 -> Loss: 1.1371608386332515, accuracy: 89.42166900634766\n",
            "epoch 44 -> Loss: 1.1671062019536458, accuracy: 89.36166381835938\n",
            "epoch 45 -> Loss: 1.1092098345364463, accuracy: 89.51000213623047\n",
            "epoch 46 -> Loss: 1.1419100816300047, accuracy: 89.43333435058594\n",
            "epoch 47 -> Loss: 1.1834341489138014, accuracy: 89.3133316040039\n",
            "epoch 48 -> Loss: 1.1636921230858481, accuracy: 89.51166534423828\n",
            "epoch 49 -> Loss: 1.1763309994017455, accuracy: 89.4749984741211\n",
            "epoch 50 -> Loss: 1.1525379117768901, accuracy: 89.40666961669922\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFmMbMB1oPSi"
      },
      "source": [
        "**test function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "R5Bae47wlgmt"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            total_correct += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {(correct / total_correct) * 100}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t5ujVJVlvA2",
        "outputId": "64b8c0d8-799e-40b2-c19e-fa1cc8f999ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.92999999999999%\n"
          ]
        }
      ],
      "source": [
        "test(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}